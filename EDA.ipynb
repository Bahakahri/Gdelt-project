{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d92424e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9464c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using Dask\n",
    "df = dd.read_csv(\"C:/Users/bahak/Gdelt project/data/PALISR/filtered.csv\", assume_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0ec008e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+----------------------+--------+----------+\n| Column               | Found  | Expected |\n+----------------------+--------+----------+\n| ActionGeo_FeatureID  | object | float64  |\n| Actor1EthnicCode     | object | float64  |\n| Actor1Geo_FeatureID  | object | float64  |\n| Actor1KnownGroupCode | object | float64  |\n| Actor1Religion1Code  | object | float64  |\n| Actor1Religion2Code  | object | float64  |\n| Actor1Type2Code      | object | float64  |\n| Actor1Type3Code      | object | float64  |\n| Actor2EthnicCode     | object | float64  |\n| Actor2Geo_FeatureID  | object | float64  |\n| Actor2KnownGroupCode | object | float64  |\n| Actor2Religion1Code  | object | float64  |\n| Actor2Religion2Code  | object | float64  |\n| Actor2Type2Code      | object | float64  |\n| Actor2Type3Code      | object | float64  |\n+----------------------+--------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- ActionGeo_FeatureID\n  ValueError(\"could not convert string to float: 'EI'\")\n- Actor1EthnicCode\n  ValueError(\"could not convert string to float: 'sco'\")\n- Actor1Geo_FeatureID\n  ValueError(\"could not convert string to float: 'EI'\")\n- Actor1KnownGroupCode\n  ValueError(\"could not convert string to float: 'IRC'\")\n- Actor1Religion1Code\n  ValueError(\"could not convert string to float: 'JEW'\")\n- Actor1Religion2Code\n  ValueError(\"could not convert string to float: 'PRO'\")\n- Actor1Type2Code\n  ValueError(\"could not convert string to float: 'HLH'\")\n- Actor1Type3Code\n  ValueError(\"could not convert string to float: 'LAB'\")\n- Actor2EthnicCode\n  ValueError(\"could not convert string to float: 'oji'\")\n- Actor2Geo_FeatureID\n  ValueError(\"could not convert string to float: 'IS'\")\n- Actor2KnownGroupCode\n  ValueError(\"could not convert string to float: 'EEC'\")\n- Actor2Religion1Code\n  ValueError(\"could not convert string to float: 'JEW'\")\n- Actor2Religion2Code\n  ValueError(\"could not convert string to float: 'PRO'\")\n- Actor2Type2Code\n  ValueError(\"could not convert string to float: 'JUD'\")\n- Actor2Type3Code\n  ValueError(\"could not convert string to float: 'MED'\")\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'ActionGeo_FeatureID': 'object',\n       'Actor1EthnicCode': 'object',\n       'Actor1Geo_FeatureID': 'object',\n       'Actor1KnownGroupCode': 'object',\n       'Actor1Religion1Code': 'object',\n       'Actor1Religion2Code': 'object',\n       'Actor1Type2Code': 'object',\n       'Actor1Type3Code': 'object',\n       'Actor2EthnicCode': 'object',\n       'Actor2Geo_FeatureID': 'object',\n       'Actor2KnownGroupCode': 'object',\n       'Actor2Religion1Code': 'object',\n       'Actor2Religion2Code': 'object',\n       'Actor2Type2Code': 'object',\n       'Actor2Type3Code': 'object'}\n\nto the call to `read_csv`/`read_table`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m actor2_isr \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActor2Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISR\u001b[39m\u001b[38;5;124m'\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Compute the filtered data (gather into Pandas DataFrame)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m actor1_pal_pse_pd \u001b[38;5;241m=\u001b[39m \u001b[43mactor1_pal_pse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m actor1_isr_pd \u001b[38;5;241m=\u001b[39m actor1_isr\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m     10\u001b[0m actor2_pal_pse_pd \u001b[38;5;241m=\u001b[39m actor2_pal_pse\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\base.py:376\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:142\u001b[0m, in \u001b[0;36mCSVFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m    139\u001b[0m         rest_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m columns\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Call `pandas_read_text`\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_read_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrest_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_after_read:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:197\u001b[0m, in \u001b[0;36mpandas_read_text\u001b[1;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001b[0m\n\u001b[0;32m    195\u001b[0m df \u001b[38;5;241m=\u001b[39m reader(bio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes:\n\u001b[1;32m--> 197\u001b[0m     \u001b[43mcoerce_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enforce \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(columns)):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns do not match\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mcolumns, columns)\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:298\u001b[0m, in \u001b[0;36mcoerce_dtypes\u001b[1;34m(df, dtypes)\u001b[0m\n\u001b[0;32m    294\u001b[0m rule \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m61\u001b[39m)\n\u001b[0;32m    295\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatched dtypes found in `pd.read_csv`/`pd.read_table`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m    296\u001b[0m     rule\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, [dtype_msg, date_msg]))\n\u001b[0;32m    297\u001b[0m )\n\u001b[1;32m--> 298\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+----------------------+--------+----------+\n| Column               | Found  | Expected |\n+----------------------+--------+----------+\n| ActionGeo_FeatureID  | object | float64  |\n| Actor1EthnicCode     | object | float64  |\n| Actor1Geo_FeatureID  | object | float64  |\n| Actor1KnownGroupCode | object | float64  |\n| Actor1Religion1Code  | object | float64  |\n| Actor1Religion2Code  | object | float64  |\n| Actor1Type2Code      | object | float64  |\n| Actor1Type3Code      | object | float64  |\n| Actor2EthnicCode     | object | float64  |\n| Actor2Geo_FeatureID  | object | float64  |\n| Actor2KnownGroupCode | object | float64  |\n| Actor2Religion1Code  | object | float64  |\n| Actor2Religion2Code  | object | float64  |\n| Actor2Type2Code      | object | float64  |\n| Actor2Type3Code      | object | float64  |\n+----------------------+--------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- ActionGeo_FeatureID\n  ValueError(\"could not convert string to float: 'EI'\")\n- Actor1EthnicCode\n  ValueError(\"could not convert string to float: 'sco'\")\n- Actor1Geo_FeatureID\n  ValueError(\"could not convert string to float: 'EI'\")\n- Actor1KnownGroupCode\n  ValueError(\"could not convert string to float: 'IRC'\")\n- Actor1Religion1Code\n  ValueError(\"could not convert string to float: 'JEW'\")\n- Actor1Religion2Code\n  ValueError(\"could not convert string to float: 'PRO'\")\n- Actor1Type2Code\n  ValueError(\"could not convert string to float: 'HLH'\")\n- Actor1Type3Code\n  ValueError(\"could not convert string to float: 'LAB'\")\n- Actor2EthnicCode\n  ValueError(\"could not convert string to float: 'oji'\")\n- Actor2Geo_FeatureID\n  ValueError(\"could not convert string to float: 'IS'\")\n- Actor2KnownGroupCode\n  ValueError(\"could not convert string to float: 'EEC'\")\n- Actor2Religion1Code\n  ValueError(\"could not convert string to float: 'JEW'\")\n- Actor2Religion2Code\n  ValueError(\"could not convert string to float: 'PRO'\")\n- Actor2Type2Code\n  ValueError(\"could not convert string to float: 'JUD'\")\n- Actor2Type3Code\n  ValueError(\"could not convert string to float: 'MED'\")\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'ActionGeo_FeatureID': 'object',\n       'Actor1EthnicCode': 'object',\n       'Actor1Geo_FeatureID': 'object',\n       'Actor1KnownGroupCode': 'object',\n       'Actor1Religion1Code': 'object',\n       'Actor1Religion2Code': 'object',\n       'Actor1Type2Code': 'object',\n       'Actor1Type3Code': 'object',\n       'Actor2EthnicCode': 'object',\n       'Actor2Geo_FeatureID': 'object',\n       'Actor2KnownGroupCode': 'object',\n       'Actor2Religion1Code': 'object',\n       'Actor2Religion2Code': 'object',\n       'Actor2Type2Code': 'object',\n       'Actor2Type3Code': 'object'}\n\nto the call to `read_csv`/`read_table`."
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter datasets\n",
    "actor1_pal_pse = df[df['Actor1Code'].str.contains('PAL|PSE', na=False)]\n",
    "actor1_isr = df[df['Actor1Code'].str.contains('ISR', na=False)]\n",
    "actor2_pal_pse = df[df['Actor2Code'].str.contains('PAL|PSE', na=False)]\n",
    "actor2_isr = df[df['Actor2Code'].str.contains('ISR', na=False)]\n",
    "\n",
    "# Compute the filtered data (gather into Pandas DataFrame)\n",
    "actor1_pal_pse_pd = actor1_pal_pse.compute()\n",
    "actor1_isr_pd = actor1_isr.compute()\n",
    "actor2_pal_pse_pd = actor2_pal_pse.compute()\n",
    "actor2_isr_pd = actor2_isr.compute()\n",
    "\n",
    "# Save each to a CSV file\n",
    "actor1_pal_pse_pd.to_csv('C:/Users/bahak/Gdelt project/data/PALISR/actor1_pal.csv', index=False)\n",
    "actor1_isr_pd.to_csv('C:/Users/bahak/Gdelt project/data/PALISR/actor1_isr.csv', index=False)\n",
    "actor2_pal_pse_pd.to_csv('C:/Users/bahak/Gdelt project/data/PALISR/actor2_pal.csv', index=False)\n",
    "actor2_isr_pd.to_csv('C:/Users/bahak/Gdelt project/data/PALISR/actor2_isr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e10de116",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+----------------------+--------+----------+\n| Column               | Found  | Expected |\n+----------------------+--------+----------+\n| ActionGeo_FeatureID  | object | float64  |\n| Actor1EthnicCode     | object | float64  |\n| Actor1Geo_FeatureID  | object | float64  |\n| Actor1KnownGroupCode | object | float64  |\n| Actor1Religion1Code  | object | float64  |\n| Actor1Religion2Code  | object | float64  |\n| Actor1Type2Code      | object | float64  |\n| Actor1Type3Code      | object | float64  |\n| Actor2EthnicCode     | object | float64  |\n| Actor2Geo_FeatureID  | object | float64  |\n| Actor2KnownGroupCode | object | float64  |\n| Actor2Religion1Code  | object | float64  |\n| Actor2Religion2Code  | object | float64  |\n| Actor2Type2Code      | object | float64  |\n| Actor2Type3Code      | object | float64  |\n+----------------------+--------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- ActionGeo_FeatureID\n  ValueError(\"could not convert string to float: 'IS'\")\n- Actor1EthnicCode\n  ValueError(\"could not convert string to float: 'smi'\")\n- Actor1Geo_FeatureID\n  ValueError(\"could not convert string to float: 'IS'\")\n- Actor1KnownGroupCode\n  ValueError(\"could not convert string to float: 'UNO'\")\n- Actor1Religion1Code\n  ValueError(\"could not convert string to float: 'JEW'\")\n- Actor1Religion2Code\n  ValueError(\"could not convert string to float: 'CTH'\")\n- Actor1Type2Code\n  ValueError(\"could not convert string to float: 'MIL'\")\n- Actor1Type3Code\n  ValueError(\"could not convert string to float: 'GOV'\")\n- Actor2EthnicCode\n  ValueError(\"could not convert string to float: 'tgl'\")\n- Actor2Geo_FeatureID\n  ValueError(\"could not convert string to float: 'IS'\")\n- Actor2KnownGroupCode\n  ValueError(\"could not convert string to float: 'UNO'\")\n- Actor2Religion1Code\n  ValueError(\"could not convert string to float: 'JEW'\")\n- Actor2Religion2Code\n  ValueError(\"could not convert string to float: 'CTH'\")\n- Actor2Type2Code\n  ValueError(\"could not convert string to float: 'EDU'\")\n- Actor2Type3Code\n  ValueError(\"could not convert string to float: 'GOV'\")\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'ActionGeo_FeatureID': 'object',\n       'Actor1EthnicCode': 'object',\n       'Actor1Geo_FeatureID': 'object',\n       'Actor1KnownGroupCode': 'object',\n       'Actor1Religion1Code': 'object',\n       'Actor1Religion2Code': 'object',\n       'Actor1Type2Code': 'object',\n       'Actor1Type3Code': 'object',\n       'Actor2EthnicCode': 'object',\n       'Actor2Geo_FeatureID': 'object',\n       'Actor2KnownGroupCode': 'object',\n       'Actor2Religion1Code': 'object',\n       'Actor2Religion2Code': 'object',\n       'Actor2Type2Code': 'object',\n       'Actor2Type3Code': 'object'}\n\nto the call to `read_csv`/`read_table`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Sample a small number of rows to check column types\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pull a few rows into pandas\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# See what columns are read as float but contain strings\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\dataframe\\core.py:1557\u001b[0m, in \u001b[0;36m_Frame.head\u001b[1;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;66;03m# No need to warn if we're already looking at all partitions\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m safe \u001b[38;5;241m=\u001b[39m npartitions \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpartitions\n\u001b[1;32m-> 1557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpartitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpartitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\dataframe\\core.py:1591\u001b[0m, in \u001b[0;36m_Frame._head\u001b[1;34m(self, n, npartitions, compute, safe)\u001b[0m\n\u001b[0;32m   1586\u001b[0m result \u001b[38;5;241m=\u001b[39m new_dd_object(\n\u001b[0;32m   1587\u001b[0m     graph, name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions[npartitions]]\n\u001b[0;32m   1588\u001b[0m )\n\u001b[0;32m   1590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[1;32m-> 1591\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\base.py:376\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:142\u001b[0m, in \u001b[0;36mCSVFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m    139\u001b[0m         rest_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m columns\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Call `pandas_read_text`\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_read_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrest_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_after_read:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:197\u001b[0m, in \u001b[0;36mpandas_read_text\u001b[1;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001b[0m\n\u001b[0;32m    195\u001b[0m df \u001b[38;5;241m=\u001b[39m reader(bio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes:\n\u001b[1;32m--> 197\u001b[0m     \u001b[43mcoerce_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enforce \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(columns)):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns do not match\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mcolumns, columns)\n",
      "File \u001b[1;32mc:\\Users\\bahak\\anaconda3\\envs\\news_env\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:298\u001b[0m, in \u001b[0;36mcoerce_dtypes\u001b[1;34m(df, dtypes)\u001b[0m\n\u001b[0;32m    294\u001b[0m rule \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m61\u001b[39m)\n\u001b[0;32m    295\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatched dtypes found in `pd.read_csv`/`pd.read_table`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m    296\u001b[0m     rule\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, [dtype_msg, date_msg]))\n\u001b[0;32m    297\u001b[0m )\n\u001b[1;32m--> 298\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+----------------------+--------+----------+\n| Column               | Found  | Expected |\n+----------------------+--------+----------+\n| ActionGeo_FeatureID  | object | float64  |\n| Actor1EthnicCode     | object | float64  |\n| Actor1Geo_FeatureID  | object | float64  |\n| Actor1KnownGroupCode | object | float64  |\n| Actor1Religion1Code  | object | float64  |\n| Actor1Religion2Code  | object | float64  |\n| Actor1Type2Code      | object | float64  |\n| Actor1Type3Code      | object | float64  |\n| Actor2EthnicCode     | object | float64  |\n| Actor2Geo_FeatureID  | object | float64  |\n| Actor2KnownGroupCode | object | float64  |\n| Actor2Religion1Code  | object | float64  |\n| Actor2Religion2Code  | object | float64  |\n| Actor2Type2Code      | object | float64  |\n| Actor2Type3Code      | object | float64  |\n+----------------------+--------+----------+\n\nThe following columns also raised exceptions on conversion:\n\n- ActionGeo_FeatureID\n  ValueError(\"could not convert string to float: 'IS'\")\n- Actor1EthnicCode\n  ValueError(\"could not convert string to float: 'smi'\")\n- Actor1Geo_FeatureID\n  ValueError(\"could not convert string to float: 'IS'\")\n- Actor1KnownGroupCode\n  ValueError(\"could not convert string to float: 'UNO'\")\n- Actor1Religion1Code\n  ValueError(\"could not convert string to float: 'JEW'\")\n- Actor1Religion2Code\n  ValueError(\"could not convert string to float: 'CTH'\")\n- Actor1Type2Code\n  ValueError(\"could not convert string to float: 'MIL'\")\n- Actor1Type3Code\n  ValueError(\"could not convert string to float: 'GOV'\")\n- Actor2EthnicCode\n  ValueError(\"could not convert string to float: 'tgl'\")\n- Actor2Geo_FeatureID\n  ValueError(\"could not convert string to float: 'IS'\")\n- Actor2KnownGroupCode\n  ValueError(\"could not convert string to float: 'UNO'\")\n- Actor2Religion1Code\n  ValueError(\"could not convert string to float: 'JEW'\")\n- Actor2Religion2Code\n  ValueError(\"could not convert string to float: 'CTH'\")\n- Actor2Type2Code\n  ValueError(\"could not convert string to float: 'EDU'\")\n- Actor2Type3Code\n  ValueError(\"could not convert string to float: 'GOV'\")\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'ActionGeo_FeatureID': 'object',\n       'Actor1EthnicCode': 'object',\n       'Actor1Geo_FeatureID': 'object',\n       'Actor1KnownGroupCode': 'object',\n       'Actor1Religion1Code': 'object',\n       'Actor1Religion2Code': 'object',\n       'Actor1Type2Code': 'object',\n       'Actor1Type3Code': 'object',\n       'Actor2EthnicCode': 'object',\n       'Actor2Geo_FeatureID': 'object',\n       'Actor2KnownGroupCode': 'object',\n       'Actor2Religion1Code': 'object',\n       'Actor2Religion2Code': 'object',\n       'Actor2Type2Code': 'object',\n       'Actor2Type3Code': 'object'}\n\nto the call to `read_csv`/`read_table`."
     ]
    }
   ],
   "source": [
    "# Sample a small number of rows to check column types\n",
    "sample = df.head(1000)  # pull a few rows into pandas\n",
    "\n",
    "# See what columns are read as float but contain strings\n",
    "for col in sample.columns:\n",
    "    try:\n",
    "        sample[col].astype(float)\n",
    "    except:\n",
    "        print(f\"Issue with column: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75db0b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBALEVENTID              int64\n",
      "SQLDATE                    int64\n",
      "MonthYear                  int64\n",
      "Year                       int64\n",
      "FractionDate             float64\n",
      "Actor1Code                object\n",
      "Actor1Name                object\n",
      "Actor1CountryCode         object\n",
      "Actor1KnownGroupCode     float64\n",
      "Actor1EthnicCode         float64\n",
      "Actor1Religion1Code       object\n",
      "Actor1Religion2Code      float64\n",
      "Actor1Type1Code           object\n",
      "Actor1Type2Code          float64\n",
      "Actor1Type3Code          float64\n",
      "Actor2Code                object\n",
      "Actor2Name                object\n",
      "Actor2CountryCode         object\n",
      "Actor2KnownGroupCode     float64\n",
      "Actor2EthnicCode         float64\n",
      "Actor2Religion1Code       object\n",
      "Actor2Religion2Code      float64\n",
      "Actor2Type1Code           object\n",
      "Actor2Type2Code          float64\n",
      "Actor2Type3Code          float64\n",
      "IsRootEvent                int64\n",
      "EventCode                  int64\n",
      "EventBaseCode              int64\n",
      "EventRootCode              int64\n",
      "QuadClass                  int64\n",
      "GoldsteinScale           float64\n",
      "NumMentions                int64\n",
      "NumSources                 int64\n",
      "NumArticles                int64\n",
      "AvgTone                  float64\n",
      "Actor1Geo_Type             int64\n",
      "Actor1Geo_FullName        object\n",
      "Actor1Geo_CountryCode     object\n",
      "Actor1Geo_ADM1Code        object\n",
      "Actor1Geo_Lat            float64\n",
      "Actor1Geo_Long           float64\n",
      "Actor1Geo_FeatureID       object\n",
      "Actor2Geo_Type             int64\n",
      "Actor2Geo_FullName        object\n",
      "Actor2Geo_CountryCode     object\n",
      "Actor2Geo_ADM1Code        object\n",
      "Actor2Geo_Lat            float64\n",
      "Actor2Geo_Long           float64\n",
      "Actor2Geo_FeatureID       object\n",
      "ActionGeo_Type             int64\n",
      "ActionGeo_FullName        object\n",
      "ActionGeo_CountryCode     object\n",
      "ActionGeo_ADM1Code        object\n",
      "ActionGeo_Lat            float64\n",
      "ActionGeo_Long           float64\n",
      "ActionGeo_FeatureID       object\n",
      "DATEADDED                  int64\n",
      "SOURCEURL                 object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sample.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f23cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
